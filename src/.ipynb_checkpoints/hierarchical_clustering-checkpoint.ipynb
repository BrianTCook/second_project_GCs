{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "import glob\n",
    "import math\n",
    "import re\n",
    "\n",
    "from cluster_table import sort_clusters_by_attribute\n",
    "\n",
    "plt.rc('text', usetex = True)\n",
    "plt.rc('font', family = 'serif')\n",
    "\n",
    "import os\n",
    "\n",
    "import json, requests\n",
    "\n",
    "from notebook import notebookapp\n",
    "servers = list(notebookapp.list_running_servers())\n",
    "localhost_name = servers[0]['url']\n",
    "\n",
    "random.seed(19680801)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>class and function definitions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMUSE_star:\n",
    "    def __init__(self, x, y, z, vx, vy, vz):\n",
    "\n",
    "        #measured data for the variable, kpc and km/s\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "        self.vx = vx\n",
    "        self.vy = vy\n",
    "        self.vz = vz\n",
    "\n",
    "def mode(vals):\n",
    "    #vals must be a list\n",
    "    return max(set(vals), key=vals.count)\n",
    "\n",
    "# returns index of list element closest to a provided value\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "# http://www.mathworks.com/matlabcentral/fileexchange/24693-ellipsoid-fit\n",
    "# for arbitrary axes\n",
    "def ellipsoid_fit(X):\n",
    "    x = X[:, 0]\n",
    "    y = X[:, 1]\n",
    "    z = X[:, 2]\n",
    "    D = np.array([x * x + y * y - 2 * z * z,\n",
    "                 x * x + z * z - 2 * y * y,\n",
    "                 2 * x * y,\n",
    "                 2 * x * z,\n",
    "                 2 * y * z,\n",
    "                 2 * x,\n",
    "                 2 * y,\n",
    "                 2 * z,\n",
    "                 1 - 0 * x])\n",
    "    d2 = np.array(x * x + y * y + z * z).T # rhs for LLSQ\n",
    "    u = np.linalg.solve(D.dot(D.T), D.dot(d2))\n",
    "    a = np.array([u[0] + 1 * u[1] - 1])\n",
    "    b = np.array([u[0] - 2 * u[1] - 1])\n",
    "    c = np.array([u[1] - 2 * u[0] - 1])\n",
    "    v = np.concatenate([a, b, c, u[2:]], axis=0).flatten()\n",
    "    A = np.array([[v[0], v[3], v[4], v[6]],\n",
    "                  [v[3], v[1], v[5], v[7]],\n",
    "                  [v[4], v[5], v[2], v[8]],\n",
    "                  [v[6], v[7], v[8], v[9]]])\n",
    "\n",
    "    center = np.linalg.solve(- A[:3, :3], v[6:9])\n",
    "\n",
    "    translation_matrix = np.eye(4)\n",
    "    translation_matrix[3, :3] = center.T\n",
    "\n",
    "    R = translation_matrix.dot(A).dot(translation_matrix.T)\n",
    "\n",
    "    evals, evecs = np.linalg.eig(R[:3, :3] / -R[3, 3])\n",
    "    evecs = evecs.T\n",
    "\n",
    "    radii = np.sqrt(1. / np.abs(evals))\n",
    "    radii *= np.sign(evals)\n",
    "\n",
    "    return center, evecs, radii\n",
    "\n",
    "#goes from index to color from the colormap cm\n",
    "def get_color(ind, N_colors):\n",
    "    \n",
    "    cm = plt.get_cmap('jet')\n",
    "    color_vals = [cm(1.*i/N_colors) for i in range(N_colors)]\n",
    "    \n",
    "    return color_vals[ind]\n",
    "\n",
    "r_sun = 8. #kpc, Vivas & Zinn 2006\n",
    "r_MW = 15.\n",
    "n0, qH, nH = 4.5, 0.71, 2.62 #kpc^-3, constants describing halo geometry\n",
    "#z_sun << r_sun, large error bar so we will assume it's 0\n",
    "\n",
    "#theoretical distribution\n",
    "def numdens_RR(R,Z):\n",
    "    return n0*(r_sun/(R**2 + (Z/qH)**2))**nH\n",
    "\n",
    "#Gaussian KDE based on distribution of ordered pairs\n",
    "def density_estimation(m1, m2):\n",
    "    #memoselyk on stack overflow\n",
    "    xmin, xmax, ymin, ymax = min(m1), max(m1), min(m2), max(m2)\n",
    "    X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]                                                     \n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])                                                       \n",
    "    values = np.vstack([m1, m2])                                                                        \n",
    "    kernel = stats.gaussian_kde(values)                                                                 \n",
    "    Z = np.reshape(kernel(positions).T, X.shape)\n",
    "    return X, Y, Z\n",
    "\n",
    "#checks a list to see if there are nans in it\n",
    "def no_nans(lst):\n",
    "    checker = [ 0 if math.isnan(lst[k]) == False else 1 for k in range(len(lst)) ]\n",
    "    if np.sum(checker) == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "'''\n",
    "Functions needed for RR Lyrae catalog to number density map of clusters pipeline\n",
    "'''\n",
    "\n",
    "#from RR_Lyrae variable objects to data frame containing RR Lyrae variable data\n",
    "def stars_matrix(snapshot, Norbiters):\n",
    "    \n",
    "    '''\n",
    "    returns matrix of all the stars in the sample\n",
    "    columns: x, y, z, vx, vy, vz\n",
    "    '''\n",
    "    \n",
    "    datadir_AMUSE = '/Users/BrianTCook/Desktop/Thesis/second_project_gcs/Enbid-2.0/AMUSE_data/'\n",
    "    filename = 'enbid_tree_frame_' + snapshot + '_Norbiters_' + str(Norbiters) + '.ascii'\n",
    "    X = np.loadtxt(datadir_AMUSE + filename)\n",
    "        \n",
    "    return X\n",
    "    \n",
    "def condensed_distances_and_linkage(X, method):\n",
    "    \n",
    "    '''\n",
    "    takes phase space coordinate matrix\n",
    "    computes separation distance, linkage matrix based on proffered method (single, average, and so on)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    X_adjusted = np.zeros(X.shape)\n",
    "    \n",
    "    for i in range(6):\n",
    "    \n",
    "        X_adjusted[:,i] = [ (x - min(X[:,i])) / () for x in X[:,i] ]\n",
    "    '''\n",
    "    \n",
    "    X_spatial = X[:, :3]\n",
    "    \n",
    "    print(X_spatial.shape)\n",
    "    \n",
    "    cds = pdist(X_spatial, 'euclidean') \n",
    "    Z = hierarchy.linkage(cds, method=method)\n",
    "    \n",
    "    return cds, Z\n",
    "\n",
    "def tree_cutter(N_cuts, N_variables, min_height, max_height, Z, N_sizes):\n",
    "    \n",
    "    '''\n",
    "    cuts up tree encoded by linkage matrix N_cut times\n",
    "    the max_height is the maximum clustering scale, so ~r_MW would be good\n",
    "    returns N_sizes clustering scales and the relevant information from Z \n",
    "    '''\n",
    "    \n",
    "    heights = np.logspace(np.log10(max_height), np.log10(min_height), N_cuts) #smallest structure is 100 pc\n",
    "    \n",
    "    tree_cuts = [ hierarchy.cut_tree(Z, height=height) for height in heights ] \n",
    "    \n",
    "    groupings_and_counts = [ np.unique(tc,  return_counts=True) for tc in tree_cuts ]\n",
    "    groupings = [ gc[0] for gc in groupings_and_counts ]\n",
    "    allocations = [ gc[1] for gc in groupings_and_counts ]\n",
    "    \n",
    "    means = [ np.mean(allocation) for allocation in allocations ]\n",
    "    stdevs = [ np.std(allocation) for allocation in allocations ]\n",
    "    \n",
    "    Js = range(4) #show N-1 levels of standard deviation\n",
    "    Ys = [ [ (means[i] + j * stdevs[i])/N_variables for i in range(N_cuts) ] for j in Js ]\n",
    "    \n",
    "    N_groups = [ len(g) for g in groupings ]\n",
    "    frac_above_3sig = [ 1./N_groups[k] * np.sum([ 1 if alloc >= Ys[3][k]*N_variables else 0 \n",
    "                        for alloc in allocations[k] ]) for k in range(N_cuts) ]\n",
    "    \n",
    "    #way to collect clustering scales, sort by best ones and then pick out local maxima\n",
    "    best_clustering_heights = sorted(frac_above_3sig, reverse=True)\n",
    "    bch_indices = []\n",
    "    ind, flag = 0, 0 #the first one can't be a peak by definition\n",
    "    \n",
    "    while flag == 0:\n",
    "        \n",
    "        if len(bch_indices) >= N_sizes or ind > N_cuts:\n",
    "            flag = 1\n",
    "        \n",
    "        try:\n",
    "            bch_value = best_clustering_heights[ind]\n",
    "            ind_to_try = frac_above_3sig.index(bch_value)\n",
    "        except:\n",
    "            flag = 1\n",
    "            \n",
    "        try:\n",
    "\n",
    "            if ind_to_try == 0:\n",
    "                \n",
    "                if frac_above_3sig[ind_to_try] > frac_above_3sig[ind_to_try+1]:\n",
    "                    if ind_to_try not in bch_indices:\n",
    "                        bch_indices.append(ind_to_try)\n",
    "                    ind += 1\n",
    "                else:\n",
    "                    ind += 1\n",
    "                \n",
    "            if ind_to_try == len(frac_above_3sig)-1:\n",
    "                \n",
    "                if frac_above_3sig[ind_to_try] > frac_above_3sig[ind_to_try-1]:\n",
    "                    if ind_to_try not in bch_indices:\n",
    "                        bch_indices.append(ind_to_try)\n",
    "                    ind += 1\n",
    "                else:\n",
    "                    ind += 1\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                if frac_above_3sig[ind_to_try] > frac_above_3sig[ind_to_try-1] and frac_above_3sig[ind_to_try] > frac_above_3sig[ind_to_try+1]:\n",
    "                    if ind_to_try not in bch_indices:\n",
    "                        bch_indices.append(ind_to_try)\n",
    "                    ind += 1\n",
    "                else:\n",
    "                    ind += 1\n",
    "                    \n",
    "        except:\n",
    "            print('problem with if/else statement')\n",
    "            flag = 1\n",
    "    \n",
    "    from_cut = [ heights, tree_cuts, groupings_and_counts, \n",
    "                 groupings, allocations, means, stdevs, bch_indices]\n",
    "    \n",
    "    return from_cut\n",
    "\n",
    "def extract_from_best_cuts(from_cut):\n",
    "    \n",
    "    heights = from_cut[0]\n",
    "    tree_cuts = from_cut[1]\n",
    "    groupings_and_counts = from_cut[2]\n",
    "    groupings = from_cut[3]\n",
    "    allocations = from_cut[4]\n",
    "    means = from_cut[5]\n",
    "    stdevs = from_cut[6]\n",
    "    bch_indices = from_cut[7]\n",
    "    \n",
    "    N_sizes_updated = len(bch_indices)\n",
    "    keep_these_groups = [0]*N_sizes_updated\n",
    "    point_colors_all = [0]*N_sizes_updated\n",
    "\n",
    "    mode_color = (0., 0., 0., 0.8)\n",
    "\n",
    "    #iterates through selected clustering scales, assigns each a variable a color based on cluster identification\n",
    "    for j in range(N_sizes_updated):\n",
    "\n",
    "        bch_i = bch_indices[j]\n",
    "\n",
    "        best_height = heights[bch_i]  \n",
    "        best_tree_cut = tree_cuts[bch_i]\n",
    "        best_grouping = groupings[bch_i]\n",
    "        best_allocation = allocations[bch_i]\n",
    "        best_mean =  float(means[bch_i])\n",
    "        best_stdev =  (stdevs[bch_i])\n",
    "\n",
    "        ktg = [ i for i in range(len(best_allocation)) if best_allocation[i] > (best_mean + 3*best_stdev) ]\n",
    "        \n",
    "        point_colors = [ get_color(ktg.index(element), len(ktg)) if element in ktg else mode_color\n",
    "                              for element in best_tree_cut ] \n",
    "        \n",
    "        keep_these_groups[j] = ktg\n",
    "        point_colors_all[j] = point_colors\n",
    "\n",
    "    return point_colors_all\n",
    "        \n",
    "def clusters_into_dataframe(N_sizes, point_colors_all, X_total, N_star_min, N_star_max, r_min, r_max):\n",
    "    \n",
    "    mode_color = (0., 0., 0., 0.8)\n",
    "    x_means, y_means, z_means, radii, N_stars, cluster_labels, eccentricities = [], [], [], [], [], [], []\n",
    "\n",
    "    N_sizes = len(point_colors_all)\n",
    "    N_variables = len(X_total)\n",
    "    \n",
    "    print('N_sizes: ', N_sizes)\n",
    "    \n",
    "    #iterates through scales\n",
    "    for j in range(N_sizes):\n",
    "\n",
    "        point_colors = point_colors_all[j]\n",
    "\n",
    "        clustered_colors = [ point_colors[k] for k in range(N_variables) if point_colors[k] != mode_color ]\n",
    "        color_list = list( set(clustered_colors) )    \n",
    "        \n",
    "        x_j, y_j, z_j, rm_j, N_j, label_j, eccentricity_j = [], [], [], [], [], [], []\n",
    "        \n",
    "        #each cluster at this scale height\n",
    "        for cl in list(color_list):\n",
    "\n",
    "            #kpc\n",
    "            xs_cl = [ X_total[k,0] for k in range(N_variables) if point_colors[k] == cl ]\n",
    "            ys_cl = [ X_total[k,1] for k in range(N_variables) if point_colors[k] == cl ] \n",
    "            zs_cl = [ X_total[k,2] for k in range(N_variables) if point_colors[k] == cl ] \n",
    "\n",
    "            N_cl = len(xs_cl)\n",
    "            \n",
    "            X_clust = np.zeros((N_cl, 3))\n",
    "    \n",
    "            X_clust[:,0] = xs_cl\n",
    "            X_clust[:,1] = ys_cl\n",
    "            X_clust[:,2] = zs_cl\n",
    "            \n",
    "            #gets ellipsoidal characteristics of the cluster\n",
    "            \n",
    "            try:\n",
    "                center_clust, evecs_clust, radii_clust = ellipsoid_fit(X_clust)\n",
    "                min_radius, max_radius = min(radii_clust), max(radii_clust)\n",
    "               \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            eccentricity = np.sqrt( 1 - (min_radius**2)/(max_radius**2) )\n",
    "            \n",
    "            if eccentricity <= 0.2 and max_radius < 0.2: #globular cluster, unlikely to find any\n",
    "\n",
    "                label_j.append( 'GC' )\n",
    "\n",
    "            elif eccentricity >= 0.7: #stellar stream\n",
    "\n",
    "                label_j.append( 'SS' )\n",
    "                \n",
    "            else:#if eccentricity > 0.2 and eccentricity < 0.7: #other Sesar-like object\n",
    "\n",
    "                label_j.append( 'Other' )\n",
    "                \n",
    "            x_j.append(np.median(xs_cl))\n",
    "            y_j.append(np.median(ys_cl))\n",
    "            z_j.append(np.median(zs_cl))\n",
    "            rm_j.append(max_radius)\n",
    "            N_j.append(N_cl)\n",
    "            eccentricity_j.append(eccentricity)\n",
    "            \n",
    "        if len(x_j) != 0:\n",
    "            \n",
    "            x_means.append(x_j)\n",
    "            y_means.append(y_j)\n",
    "            z_means.append(z_j)\n",
    "            radii.append(rm_j)\n",
    "            N_stars.append(N_j)\n",
    "            cluster_labels.append(label_j)\n",
    "            eccentricities.append(eccentricity_j)\n",
    "    \n",
    "    x_means = [ j for i in x_means for j in i] \n",
    "    y_means = [ j for i in y_means for j in i] \n",
    "    z_means = [ j for i in z_means for j in i] \n",
    "    radii = [ j for i in radii for j in i] \n",
    "    N_stars = [ j for i in N_stars for j in i] \n",
    "    cluster_labels = [ j for i in cluster_labels for j in i] \n",
    "    eccentricities = [ j for i in eccentricities for j in i] \n",
    "    \n",
    "    headers = ['X', 'Y', 'Z', 'Radius', 'Nstars', 'Cluster Tag', 'Eccentricity' ]\n",
    "    data = [ x_means, y_means, z_means, radii, N_stars, cluster_labels, eccentricities ]\n",
    "    \n",
    "    data_dictionary = {}\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        data_dictionary.update( {header : data[i]} )\n",
    "    \n",
    "    df_all = pd.DataFrame(data=data_dictionary)\n",
    "    \n",
    "    #matching initial star cluster attributes\n",
    "    df = df_all[df_all['Nstars'] >= N_star_min]\n",
    "    df = df[df['Nstars'] <= N_star_max]\n",
    "\n",
    "    df = df[df['Radius'] >= r_min]\n",
    "    df = df[df['Radius'] <= r_max]\n",
    "\n",
    "    #gets rid of redundant clusters, rounds and stores N_stars as an integer\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.round(3)\n",
    "    df['Nstars'] = df['Nstars'].astype(int)\n",
    "    \n",
    "    #drop rows with nans in them\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = df.sort_values(by=['Nstars'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    return df, df.to_latex(index=True)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>plotting things</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#condensed distance matrix histograms\n",
    "def sep_dist_distributions(condensed_distances_matrix, condensed_distances_matrix_theory, deltaM):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.hist(condensed_distances_matrix, bins=50, histtype='step', \n",
    "             color='g', density=True, label=r'Combined Catalog, $\\delta M_{V} = %.02f$'%(deltaM))\n",
    "        \n",
    "    plt.hist(condensed_distances_matrix_theory, bins=50, histtype='step',\n",
    "             color='r', density=True, label=r'From $\\rho_{\\mathrm{model}}^{RR}(R,Z)$')\n",
    "    \n",
    "    plt.legend(loc='best', fontsize=16)\n",
    "    plt.xlabel('$D(\\mathbf{r}_{i}, \\mathbf{r}_{j})$ (kpc)', fontsize=20)\n",
    "    plt.ylabel('Normalized Distribution', fontsize=16)\n",
    "    plt.gca().tick_params(axis='both', labelsize='large')\n",
    "    plt.title('Condensed Distance Matrix Elements', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('distances_distribution_total.pdf')\n",
    "  \n",
    "def cluster_population_stat_plot(N_variables, N_cuts, heights, means, stdevs):\n",
    "    \n",
    "    Js = range(4)\n",
    "    Ys = [ [ (means[i] + j * stdevs[i])/N_variables for i in range(N_cuts) ] for j in Js ]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for j in Js:\n",
    "        if j == 0:\n",
    "            plt.loglog(heights,Ys[j], 'k', linewidth=0.75, label=r'$\\mu$')\n",
    "        else:\n",
    "            plt.loglog(heights,Ys[j], linewidth=0.75, label=r'$\\mu + %i \\sigma$'%(j))\n",
    "\n",
    "    plt.ylim(1./N_variables,1.)\n",
    "    plt.legend(loc='best', fontsize = 14)\n",
    "    #plt.title('%s'%(catalog_name), fontsize=20)\n",
    "    plt.xlabel(r'$\\min\\left(L(r,s)\\right)$ (kpc)', fontsize=20)\n",
    "    plt.ylabel(r'Variables Per Cluster (normalized)', fontsize=14)\n",
    "    plt.gca().tick_params(axis='both', labelsize='x-large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('means_and_stdevs_total.pdf') #_%s.pdf'%(catalog_name))\n",
    "\n",
    "def clustering_peak_plot(N_variables, N_cuts, heights, groupings, allocations, means, stdevs, bch_indices):\n",
    "    \n",
    "    N_groups = [ len(g) for g in groupings ]\n",
    "\n",
    "    Js = range(4)\n",
    "    Ys = [ [ (means[i] + j * stdevs[i])/N_variables for i in range(N_cuts) ] for j in Js ]\n",
    "    \n",
    "    frac_above_3sig = [ 1./N_groups[k] * np.sum([ 1 if alloc >= Ys[3][k]*N_variables else 0 \n",
    "                        for alloc in allocations[k] ]) for k in range(N_cuts)]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.semilogx(heights, frac_above_3sig, 'k', linewidth=0.75)\n",
    "    plt.xlim(min(heights),max(heights))\n",
    "    #plt.title('%s'%(catalog_name), fontsize=20)\n",
    "    plt.xlabel(r'$\\min\\left(L(r,s)\\right)$ (kpc)', fontsize=20)\n",
    "    plt.ylabel(r'$N_{\\mathrm{clusters}}$ ($N_{\\mathrm{variables}} \\geq \\mu + 3\\sigma$) (normalized)', fontsize=10)\n",
    "\n",
    "    #need to control for case where sigma > mu, indicating not a good clustering\n",
    "    best_clustering_heights = sorted(frac_above_3sig, reverse=True)\n",
    "    \n",
    "    ci = 0\n",
    "\n",
    "    N_colors = len(bch_indices)\n",
    "    \n",
    "    for bch_i in bch_indices:\n",
    "        plt.axvline(x=heights[bch_i], linewidth=0.5, \n",
    "                    color=get_color(ci, N_colors), label = '%.02f kpc'%(heights[bch_i]))\n",
    "        ci += 1\n",
    "\n",
    "    plt.xlim(0, max(heights)+2)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=6)  \n",
    "    plt.gca().tick_params(axis='both', labelsize='large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('finding_clustering_peaks_total.pdf') #_%s.pdf'%(catalog_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>going through several RR Lyrae catalogs</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    print('main has started!')\n",
    "    t0 = time.time()\n",
    "    \n",
    "    snapshot, Norbiters = '00000', 16\n",
    "    \n",
    "    X_total = stars_matrix(snapshot, Norbiters)\n",
    "    N_variables = len(X_total[:,0])\n",
    "\n",
    "    method = 'average'\n",
    "    cds, Z = condensed_distances_and_linkage(X_total, method)   \n",
    "    \n",
    "    datadir_data = '/Users/BrianTCook/Desktop/Thesis/second_project_gcs/data/'\n",
    "    cluster_populations = list( np.loadtxt(datadir_data + 'Nstars_in_clusters.txt') ) \n",
    "    cluster_radii = list( np.loadtxt(datadir_data + 'ICs/cluster_radii_for_sampling.txt') )\n",
    "    \n",
    "    #need to give clusters sorted by an attribute, in our case increasing |r|\n",
    "    #new_index = indices_dict[old_index]\n",
    "    indices_dict = sort_clusters_by_attribute('|r|')\n",
    "    \n",
    "    cluster_populations_sorted = [ int(cluster_populations[indices_dict[i]]) for i in range(Norbiters) ]\n",
    "    cluster_radii_sorted = [ cluster_radii[indices_dict[i]] for i in range(Norbiters) ]\n",
    "\n",
    "    for k, number_of_stars in enumerate(cluster_populations_sorted):\n",
    "        \n",
    "        starting_index = int(np.sum( cluster_populations_sorted[:k] ))\n",
    "        ending_index = starting_index + int(number_of_stars)\n",
    "        \n",
    "        print('%i th cluster: (%.03f, %.03f, %.03f) kpc'%(k, np.median(X_total[starting_index:ending_index, 0]),\n",
    "                                                          np.median(X_total[starting_index:ending_index, 1]),\n",
    "                                                          np.median(X_total[starting_index:ending_index, 2])))\n",
    "\n",
    "    N_star_min, N_star_max = 0.9*min(cluster_populations_sorted) , 1.1*max(cluster_populations_sorted)\n",
    "    r_min, r_max = 0.1*min(cluster_radii_sorted)/1000., 10.*max(cluster_radii_sorted)/1000. #in kpc\n",
    "\n",
    "    print('r_min, r_max: ', r_min, r_max)\n",
    "    \n",
    "    N_sizes, N_cuts, min_height, max_height = 50, 100, 1e-4, 2e-2 #max_height ~ r_MW\n",
    "    from_cut = tree_cutter(N_cuts, N_variables, min_height, max_height, Z, N_sizes)\n",
    "    \n",
    "    heights = from_cut[0]\n",
    "    tree_cuts = from_cut[1]\n",
    "    groupings_and_counts = from_cut[2]\n",
    "    groupings = from_cut[3]\n",
    "    allocations = from_cut[4]\n",
    "    means = from_cut[5]\n",
    "    stdevs = from_cut[6]\n",
    "    bch_indices = from_cut[7]\n",
    "\n",
    "    point_colors_all = extract_from_best_cuts(from_cut)\n",
    "    \n",
    "    #get clusters\n",
    "    df, df_as_latex = clusters_into_dataframe(N_sizes, point_colors_all, \n",
    "                                              X_total, N_star_min, N_star_max, r_min, r_max)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_as_latex = df.to_latex(index=True) \n",
    "\n",
    "    print('have catalog of clusters, time = %.02f minutes'%((time.time()-t0)/60.))\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main has started!\n",
      "(8761, 3)\n",
      "0 th cluster: (-0.005, -0.004, -0.018) kpc\n",
      "1 th cluster: (-0.012, 0.008, -0.012) kpc\n",
      "2 th cluster: (-0.032, -0.026, 0.023) kpc\n",
      "3 th cluster: (-0.008, -0.021, 0.043) kpc\n",
      "4 th cluster: (-0.046, -0.031, -0.010) kpc\n",
      "5 th cluster: (0.049, -0.027, -0.014) kpc\n",
      "6 th cluster: (0.040, 0.059, 0.052) kpc\n",
      "7 th cluster: (0.076, -0.070, -0.084) kpc\n",
      "8 th cluster: (0.070, 0.073, -0.094) kpc\n",
      "9 th cluster: (-0.135, -0.023, -0.033) kpc\n",
      "10 th cluster: (-0.139, 0.016, -0.019) kpc\n",
      "11 th cluster: (-0.065, 0.064, 0.109) kpc\n",
      "12 th cluster: (-0.056, 0.131, 0.017) kpc\n",
      "13 th cluster: (-0.102, 0.030, -0.107) kpc\n",
      "14 th cluster: (-0.124, 0.062, 0.153) kpc\n",
      "15 th cluster: (-0.268, 0.027, 0.038) kpc\n",
      "r_min, r_max:  3.724962826067282e-05 0.0694076334843335\n",
      "N_sizes:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:306: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X      Y      Z  Radius  Nstars Cluster Tag  Eccentricity\n",
      "0 -0.012  0.008 -0.012   0.000     244          SS         0.783\n",
      "1 -0.056  0.131  0.017   0.000     251          SS         0.913\n",
      "2  0.076 -0.070 -0.084   0.001     266          SS         0.938\n",
      "3 -0.139  0.016 -0.019   0.000     272          SS         0.791\n",
      "4 -0.012  0.008 -0.012   0.000     282          SS         0.741\n",
      "have catalog of clusters, time = 6.39 minutes\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ in '__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
